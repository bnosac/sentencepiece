% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bpemb.R
\name{sentencepiece_download_model}
\alias{sentencepiece_download_model}
\title{Download a Sentencepiece model}
\usage{
sentencepiece_download_model(language, vocab_size, dim,
  model_dir = system.file(package = "sentencepiece", "models"),
  type = "bpemb")
}
\arguments{
\item{language}{a character string with the language name}

\item{vocab_size}{integer indicating the number of tokens in the final vocabulary. Defaults to 5000.}

\item{dim}{dimension of the embedding. Either 25, 50, 100, 200 or 300.}

\item{model_dir}{path to the location where the model will be downloaded to}

\item{type}{currently only 'bpemb' is allowed indicating to download models available at \url{https://github.com/bheinzerling/bpemb}}
}
\value{
a list with elements 
\itemize{
\item{language: the provide language}
\item{wikicode: the wikipedia code of the provided language}
\item{file_model: the path to the Sentencepiece model}
\item{url: the url where the model was fetched from}
\item{download_failed: logical, indicating if the download failed}
\item{download_message: a character string with possible download failure information}
\item{glove: a list with elements file_model, url, download_failed and download_message indicating the path to the Glove embeddings. Only present if the dim argument is provided in the function. Otherwise the embeddings will not be downloaded}
}
}
\description{
Download a pre-trained Sentencepiece model. \cr
The function \code{sentencepiece_download_model} allows to download pretrained models built on Wikipedia
made available at \url{https://github.com/bheinzerling/bpemb}. These models contain Byte Pair Encoded models as well
as Glove embeddings of these Byte Pair subwords.
}
\examples{
##
## Download only the tokeniser model
##
dl <- sentencepiece_download_model("Russian", vocab_size = 1000)
dl <- sentencepiece_download_model("English", vocab_size = 1000)
dl <- sentencepiece_download_model("French", vocab_size = 1000)
dl <- sentencepiece_download_model("Vlaams", vocab_size = 1000)
dl <- sentencepiece_download_model("Dutch", vocab_size = 1000)
dl <- sentencepiece_download_model("nl", vocab_size = 1000)
str(dl)
model     <- sentencepiece_load_model(dl$file_model)

##
## Download the tokeniser model + Glove embeddings of Byte Pairs
##
dl <- sentencepiece_download_model("nl", vocab_size = 1000, dim = 50)
str(dl)
model     <- sentencepiece_load_model(dl$file_model)
embedding <- read_word2vec(dl$glove$file_model)
}
\seealso{
\code{\link{sentencepiece_load_model}}
}
