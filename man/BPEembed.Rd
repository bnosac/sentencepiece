% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bpemb.R
\name{BPEembed}
\alias{BPEembed}
\title{Tokenise and embed text alongside a Sentencepiece and Word2vec model}
\usage{
BPEembed(file_sentencepiece, file_word2vec, x, normalize = TRUE)
}
\arguments{
\item{file_sentencepiece}{the path to the file containing the sentencepiece model}

\item{file_word2vec}{the path to the file containing the word2vec embeddings}

\item{x}{the result of a call to \code{\link{sentencepiece_download_model}}}

\item{normalize}{passed on to \code{\link[word2vec]{read.wordvectors}}. Defaults to \code{TRUE}.}
}
\value{
an object of class BPEembed which is a list with elements 
\itemize{
\item{model: a sentencepiece model as loaded with \code{\link{sentencepiece_load_model}}}
\item{embedding: a matrix with embeddings as loaded with \code{\link[word2vec]{read.wordvectors}}}
\item{dim: the dimension of the embedding}
\item{n: the number of elements in the vocabulary}
\item{file_sentencepiece: the sentencepiece model file}
\item{file_word2vec: the word2vec embedding file}
}
}
\description{
Use a sentencepiece model to tokenise text and get the embeddings of these
}
\examples{
## Example downloading model
path <- getwd()
\dontshow{
path <- tempdir()
}
\donttest{
dl <- sentencepiece_download_model("nl", vocab_size = 1000, dim = 50, model_dir = path)
encoder <- BPEembed(x = dl)
encoder
}
\dontshow{
# clean up for CRAN
f <- list.files(tempdir(), pattern = ".vocab$|.model$", full.names = TRUE)
invisible(file.remove(f))
}
## Example loading model from disk
embedding <- system.file(package = "sentencepiece", "models", 
                         "nl.wiki.bpe.vs1000.d25.w2v.bin")
model     <- system.file(package = "sentencepiece", "models", 
                         "nl.wiki.bpe.vs1000.model")  
encoder   <- BPEembed(model, embedding)  

txt <- c("De eigendomsoverdracht aan de deelstaten is ingewikkeld.",
         "On est d'accord sur le prix de la biere?")
values <- predict(encoder, txt, type = "encode")  
str(values) 
values

txt <- rownames(values[[1]])
predict(encoder, txt, type = "decode") 
txt <- lapply(values, FUN = rownames) 
predict(encoder, txt, type = "decode") 
}
\seealso{
\code{\link{predict.BPEembed}}, \code{\link{sentencepiece_load_model}}, \code{\link{sentencepiece_download_model}}, \code{\link[word2vec]{read.wordvectors}}
}
